<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE TEI.2 SYSTEM "tei_bawe.dtd"><TEI.2 id="_0235b" n="version 1.0"><teiHeader><fileDesc><titleStmt><title>Can functionalism provide a cross-species concept of pain?</title></titleStmt><extent/><publicationStmt><distributor>British Academic Written English (BAWE) corpus</distributor><availability><p>The British Academic Written English (BAWE) corpus was developed at the Universities of Warwick, Reading and Oxford Brookes, under the directorship of Hilary Nesi and Sheena Gardner (formerly of the Centre for Applied Linguistics [previously called CELTE], Warwick), Paul Thompson (Department of Applied Linguistics, Reading) and Paul Wickens (Westminster Institute of Education, Oxford Brookes), with funding from the ESRC. Subject to the rights of the these institutions in the BAWE corpus, and pursuant to the ESRC agreement, the BAWE corpus is available to researchers for research purposes PROVIDED THAT the following conditions are met:</p><p>1. The corpus files are not distributed in either their original form or in modified form.</p><p>2. The texts are used for research purposes only; they should not be reproduced in teaching materials.</p><p>3. The texts are not reproduced in full for a wider audience/readership, although researchers are free to quote short passages of text (up to 200 running words from any given text).</p><p>4. The BAWE corpus developers (contact: Hilary Nesi) are informed of all projects, dissertations, theses, presentations or publications arising from analysis of the corpus.</p><p>5. Researchers acknowledge their use of the corpus using the following form of words: "The data in this study come from the British Academic Written English (BAWE) corpus, which was developed at the Universities of Warwick, Reading and Oxford Brookes under the directorship of Hilary Nesi and Sheena Gardner (formerly of the Centre for Applied Linguistics [previously called CELTE], Warwick), Paul Thompson (Department of Applied Linguistics, Reading) and Paul Wickens (Westminster Institute of Education, Oxford Brookes), with funding from the ESRC (RES-000-23-0800)."</p></availability></publicationStmt><notesStmt><note resp="British Academic Written English (BAWE) corpus project">deleted: header: student name, page numbers
</note></notesStmt><sourceDesc><p n="level">2</p><p n="date">2005-11</p><p n="module title">Philosophy of Mind I</p><p n="module code">PH240</p><p n="genre family">Essay</p><p n="discipline">Philosophy</p><p n="disciplinary group">AH</p><p n="grade">D</p><p n="number of authors">1</p><p n="number of words">2552</p><p n="number of s-units">101</p><p n="number of p">25</p><p n="number of tables">0</p><p n="number of figures">0</p><p n="number of block quotes">0</p><p n="number of formulae">0</p><p n="number of lists">0</p><p n="number of paragraphs formatted like lists">4</p><p n="abstract present">no abstract</p><p n="average words per s-unit">25.3</p><p n="average s-units per p">4.0</p><p n="macrotype of assignment">simple assignment</p></sourceDesc></fileDesc><encodingDesc><p>TEI P4 (documented in: BAWE.documentation.pdf)</p></encodingDesc><profileDesc><particDesc><person><p n="gender">m</p><p n="year of birth">1981</p><p n="first language">English</p><p n="education">UKA</p><p n="course">Philosophy</p><p n="student ID">0235</p></person></particDesc></profileDesc></teiHeader><text><front><titlePage><docTitle><titlePart rend="bold">Can functionalism provide a cross-species concept of pain? </titlePart></docTitle></titlePage></front><body><div1 type="section"><p n="p1.25"><s n="s1.4;p1.25">One of the benefits claimed for the adoption of functionalism by Hilary Putnam<ref target="BAWE_0235b-ftnote.001"/> is that it allows us to avoid the charge of chauvinism that has been levelled at type/type identity theories. </s><s n="s2.4;p1.25">This charge amounts to the claim that if pain is identical with a particular process in the human brain, no creature that is not human - or doesn't have a brain of near-identical structure - can have pains. </s><s n="s3.4;p1.25">My essay will argue that functionalism cannot avoid this distinction, and will therefore only in passing raise the issue of the viability of functionalism. </s><s n="s4.4;p1.25">I shall, however, conclude by considering how much it is problematic for functionalism that it cannot answer this charge. </s></p><note place="foot" id="BAWE_0235b-ftnote.001"><p n="pn1.1"><s n="s1.2;pn1.1">Putnam, H. </s><s n="s2.2;pn1.1">'The Nature of Mental States', in (1991) <hi rend="italic">The Nature of Mind</hi>, (ed) Rosenthal, D. New York: OUP. </s></p></note><p n="p2.25"><s n="s1.2;p2.25">Functionalism claims that to bring mental states within the ambit of the physical sciences can best be achieved through an analysis of such states into their functional roles. </s><s n="s2.2;p2.25">Thus we are to consider the internal states of a human being as being defined as whatever takes the organism from one state to another.<ref target="BAWE_0235b-ftnote.002"/> Such a loose definition allows for neutrality regarding the possession of distinctly mental as opposed to physical states, Putnam claims<ref target="BAWE_0235b-ftnote.003"/>, although I will be questioning this later in my essay. </s></p><note place="foot" id="BAWE_0235b-ftnote.002"><p n="pn1.1"><s n="s1.1;pn1.1">I am here taking it that an agent, in passing from state 'a' to state 'b', identical in every respects except in that an action has been performed is undergoing a change of state. </s></p></note><note place="foot" id="BAWE_0235b-ftnote.003"><p n="pn1.1"><s n="s1.1;pn1.1">ibid p.199-200 This is clearly the significance of his silence on the question of mind and brain and his insistence on describing functional states as states of <hi rend="italic">the whole organism</hi>. </s></p></note><p n="p3.25"><s n="s1.4;p3.25">We can give a basic tripartite specification needed for a full characterization of any functional role: (1) the input conditions upon which the state is called into action, (2) the performing of the function, (3) the output produced. </s><s n="s2.4;p3.25">Of course, not all functional roles are fulfilled by states that receive <hi rend="italic">sensory</hi> inputs and produce <hi rend="italic">behavioural</hi> outputs. </s><s n="s3.4;p3.25">Many functional roles are fulfilled by states that pass from one internal state to another, just as within a computer a command inputted on the keyboard can result in the passing from one to another of a chain of internal states and only after many such applications will a change be noticed on the screen. </s><s n="s4.4;p3.25">In these cases the input conditions and the outputs are other states of the organism. </s></p><p n="p4.25"><s n="s1.3;p4.25">I am going to examine a functional analysis of pain. </s><s n="s2.3;p4.25">I shall assume that it is a state with a very simple structure: sensory perception, internal chicanery, behavioural output. </s><s n="s3.3;p4.25">It shall very soon become clear that there are problems on this account that are only magnified when we develop a more sophisticated structure. </s></p><p n="p5.25"><s n="s1.4;p5.25">If Putnam is correct, the function of pain as defined must admit of application to both fish and humans. </s><s n="s2.4;p5.25">Therefore it must admit of being related to the inputs and outputs possible for these species. </s><s n="s3.4;p5.25">The functional definition of pain must be couched in terms that admit of application to both fish and humans. </s><s n="s4.4;p5.25">We have two questions that I shall state and then answer together: </s></p><p rend="ordered" n="p6.25"><s n="s1.1;p6.25">(1) How can the sensory input of a fish be specified in the same way as the sensory input of a human being? </s></p><p rend="ordered" n="p7.25"><s n="s1.1;p7.25">(2) How can the behaviour (the output) of a fish be specified in the same way as that of a human being? </s></p><p n="p8.25"><s n="s1.5;p8.25">We can see that we have a problem if we define inputs and outputs in terms of sensory data and physical movements, as neither the sensory organs nor the physical movements of fish and humans are very similar. </s><s n="s2.5;p8.25">I do not know the details of the sensory apparatus of the fish but I here ask the reader to agree that at the least there are <hi rend="italic">some</hi> species that do not have the same perceptual experiences as humans. </s><s n="s3.5;p8.25">For sure we know that as regards behaviour fish cannot wave their arms or shout help, so a functional definition that makes use of these specific terms cannot get off the ground. </s><s n="s4.5;p8.25">We will therefore wish to characterise the inputs and outputs more generally. </s><s n="s5.5;p8.25">As a stab at that we can define pain as that function that takes the organism from tissue damage to aversion behaviour. </s></p><p n="p9.25"><s n="s1.4;p9.25">One might object that this definition allows too much as pain, and thus falls foul of one of the snares awaiting behaviourism. </s><s n="s2.4;p9.25">If we are to allow that an animal could be in pain without having a particular sensation of pain, we are already doing damage to our understanding of pain: that it, as Kripke writes, "Just is the sensation of pain." </s><ref target="BAWE_0235b-ftnote.004"/><s n="s3.4;p9.25">No notion of the <hi rend="italic">sensation</hi> of pain has entered into our definition. </s><s n="s4.4;p9.25">The functionalist may wish to accept this anti-mentalist consequence and take the behaviourist line. </s></p><note place="foot" id="BAWE_0235b-ftnote.004"><p n="pn1.1"><s n="s1.3;pn1.1">Kripke, S. </s><s n="s2.3;pn1.1">'Naming and Necessity' in (1991) <hi rend="italic">The Nature of Mind,</hi> Rosenthal, D. (ed) </s><s n="s3.3;pn1.1">New York: OUP. </s></p></note><p n="p10.25"><s n="s1.2;p10.25">There is another problem that is also familiar to behaviourism's critics and defenders: the current definition allows that those humans who can exactly replicate pain behaviour are in pain. </s><s n="s2.2;p10.25">The question of whether this is possible is irrelevant, the na√Øve-functionalist and any behaviourist would have to accept that <hi rend="italic">if</hi> it was so, that person would be in pain. </s></p><p n="p11.25"><s n="s1.2;p11.25">The first problem doesn't have to arise for functionalism if it agrees to suspend judgement on the question of whether there are distinctly mental states or properties, as I have suggested functionalism should do above. </s><s n="s2.2;p11.25">About the second problem - which is also neutral as to the mind/body problem - the functionalist can retort that it is the absence of the requisite input that is the problem. </s></p><p n="p12.25"><s n="s1.9;p12.25">This reply says it is the fact that the correct <hi rend="italic">input</hi> is not there that means that these cases are not pain, the presence of the behaviour (output) alone cannot do it. </s><s n="s2.9;p12.25">However, this will not do: the input condition will not work as it is. </s><s n="s3.9;p12.25">Tissue damage is not necessary for pain. </s><s n="s4.9;p12.25">If a family member dies, one feels pain, there is no question, and there is no tissue damage. </s><s n="s5.9;p12.25">If this is ruled admissible as it is not physical pain we can raise other examples: in the case of Chinese water torture there is no tissue damage yet there is physical pain.<ref target="BAWE_0235b-ftnote.005"/> One may also wish to consider pain felt in phantom limbs in this respect. </s><s n="s6.9;p12.25">The pain is felt as being in a limb that is no longer there, and can indeed produce aversion behaviour. </s><s n="s7.9;p12.25">If the functionalist attempts to accept these consequences and disallow those states to be pain which do not have tissue damage as their input, he will be left with a definition that doesn't take the sensation of pain to be relevant to the possession of the state and that defines someone who has the sensation of pain and is desperately trying to get out of his chains to escape the drip to not be in pain, as the input condition is not correct. </s><s n="s8.9;p12.25">Surely it is absurd to suggest that someone who feels pain and has the appropriate output is not in pain? </s><s n="s9.9;p12.25">The problem of characterising the input must lead us to conclude that this definition will not suffice to define pain in humans, therefore cannot do so for humans and fish. </s></p><note place="foot" id="BAWE_0235b-ftnote.005"><p n="pn1.1"><s n="s1.3;pn1.1">Chinese water torture consists in allowing a steady drop of water to fall on the forehead of a bound victim. </s><s n="s2.3;pn1.1">Pain ensues and frequently insanity. </s><s n="s3.3;pn1.1">Consider also the pain caused by trapped nerves. </s></p></note><p n="p13.25"><s n="s1.6;p13.25">However, there is another problem, this one with the output. </s><s n="s2.6;p13.25">Can you just define behaviour as aversion behaviour without specifying further? </s><s n="s3.6;p13.25">If you don't specify the behaviour - 'waving arms around or running away' for example - in terms of what it actually is as physical behaviour then the condition for the presence of the state can be nothing to do with the behaviour per se, as your only other option is to specify it in terms of the state (the input and inner state). </s><s n="s4.6;p13.25">Therefore the behaviour carries no weight; it is defined just as the behaviour produced by certain input conditions and inner states.<ref target="BAWE_0235b-ftnote.006"/> For our purposes - defining states in terms of what they do in taking organisms from inputs to outputs - the output has become irrelevant. </s><s n="s5.6;p13.25">All the work must be done by the input; in this light our definition becomes: pain is that state that takes an organism from tissue damage to whatever behaviour it takes it to. </s><s n="s6.6;p13.25">Given that we have already seen that tissue damage is not sufficient as an input, we are left with our definition of pain as being that state which takes us from an input that doesn't work to whatever behaviour results from it. </s></p><note place="foot" id="BAWE_0235b-ftnote.006"><p n="pn1.1"><s n="s1.2;pn1.1">For the possibility of disjunctive definitions see below, this page. </s><s n="s2.2;pn1.1">In the case of some characterisation of the behaviour as 'that behaviour caused by the nervous system in the case of x': (1) x is a state or input, and (2) - conclusively - not all organisms have nervous systems. </s></p></note><p n="p14.25"><s n="s1.3;p14.25">Clearly something needs to be refined to save cross-species functionalism here. </s><s n="s2.3;p14.25">We have seen that the rough definition leads to unacceptable results if the input is restricted to tissue damage. </s><s n="s3.3;p14.25">We can refine things two ways, by (1) altering the definition or (2) creating a disjunction. </s></p><p rend="ordered" n="p15.25"><s n="s1.6;p15.25">(1) I take it that to define the input conditions in <hi rend="italic">looser</hi> physical terms could only be in the form of a disjunctive definition (given that not all <hi rend="italic">physical</hi> damage of any type would lead to 'aversion behaviour' in different organisms), for which see below. </s><s n="s2.6;p15.25">To specify the input conditions in <hi rend="italic">tighter</hi> physical terms will not deal with our problem, given that we want it to cover more cases. </s><s n="s3.6;p15.25">For example, it must cover those cases in humans in which tissue damage is not the input. </s><s n="s4.6;p15.25">Further, we can not discount the possibility that other organisms may not be in pain when they receive tissue damage and may indeed be in pain when there has been no tissue damage. </s><s n="s5.6;p15.25">We have already lost the possibility that computers can be included as having pain, something that may irk the functionalist. </s><s n="s6.6;p15.25">Regarding biological organisms, we are in the position where a complete empirical investigation of all biological organisms would be necessary to decide whether they could be included under this definition. </s></p><p n="p16.25"><s n="s1.5;p16.25">Let us assume now what we have already argued for: such a definition of input conditions under a general heading is hopeless. </s><s n="s2.5;p16.25">We have seen tissue damage will not do it, and have seen why any further such definition is implausible. </s><s n="s3.5;p16.25">Let us also assume such an empirical investigation as has been suggested will, as a consequence produce states that we wish to call pain many of which have different input conditions, which cannot be specified generally. </s><s n="s4.5;p16.25">We have also already seen that the output conditions cannot be defined vaguely. </s><s n="s5.5;p16.25">What could we do as a cross-species functionalist? </s></p><p rend="ordered" n="p17.25"><s n="s1.4;p17.25">(2) The remaining option is disjunctive. </s><s n="s2.4;p17.25">We may wish to say that pain is that state characterised by inputs AvBvCv...vn, and outputs MvNvPv...vn. </s><s n="s3.4;p17.25">But this only makes sense as a definition <hi rend="italic">of a single function</hi> if all those states are characterised under some more general category and if conditions are included in the functional states whereby some have no affect on the organism. </s><s n="s4.4;p17.25">I shall explain. </s></p><p n="p18.25"><s n="s1.3;p18.25">The critical point of all of the preceding discussion is that at some point in our attempts to give definitions of functions an asymmetry in the definitional requirements of different organisms will necessarily arise. </s><s n="s2.3;p18.25">Conditions will have to be included in the cross-species definition which will not be necessary to give the definition for <hi rend="italic">some</hi> of the target species (which, remember, is all species). </s><s n="s3.3;p18.25">I shall now show why this is a problem for functionalism's claim to give a cross-species concept of pain. </s></p><p n="p19.25"><s n="s1.4;p19.25">We specified that functional states can form internal chains of processes. </s><s n="s2.4;p19.25">That is to say, we can include all these conditions in the form of separate states with conditions of activation. </s><s n="s3.4;p19.25">A functional state X can produce different outputs by either taking us straight to an output or by taking us to a further state that then takes us to an output. </s><s n="s4.4;p19.25">X can lead us to output O or to Y which may lead to O or, in fact to Z; it may even lead us back to X. </s></p><p n="p20.25"><s n="s1.3;p20.25">Now, we have said that there must be conditions included in our definition of pain which do not correspond to any physical possibility in some of the target organisms. </s><s n="s2.3;p20.25">For example, there is no need to include a caveat that a frog is in pain if its input is I, and its output O, <hi rend="italic">ceteris paribus</hi>, and it does not have a desire to pretend it is in pain. </s><s n="s3.3;p20.25">Frogs just don't have a thespian community. </s></p><p n="p21.25"><s n="s1.2;p21.25">We can now see clearly what Searle has described as functionalism's dualist assumption.<ref target="BAWE_0235b-ftnote.007"/> We can also see that functionalism's claim to be neutral about the physical and the mental can be called into question. </s><s n="s2.2;p21.25">I shall then outline how problems increase for more complex states than pain before concluding. </s></p><note place="foot" id="BAWE_0235b-ftnote.007"><p n="pn1.1"><s n="s1.2;pn1.1">Searle, JR. 'Minds, Brains and Programs' in (1991) <hi rend="italic">The Nature of Mind</hi>, ed. </s><s n="s2.2;pn1.1">Rosenthal, D. New York: OUP. p.519 </s></p></note><p n="p22.25"><s n="s1.13;p22.25">Searle writes: "In functionalism ... what matters are programs, and programs are independent of their realization in machines." </s><s n="s2.13;p22.25">Searle's criticisms are directed against these assumptions and are directed primarily against AI theorists. </s><s n="s3.13;p22.25">However they illuminate our discussion in two ways. </s><s n="s4.13;p22.25">First by pointing to a fact we have discovered independently: to create a cross-species concept of pain one would need to include in the specification of the state clauses which have no physical realization. </s><s n="s5.13;p22.25">There is no physical circuitry in a frog corresponding to the redundant possibility of pretending to be in pain if y. </s><s n="s6.13;p22.25">Such a functional cross-species definition is thus only possible if the state has a non-physical component. </s><s n="s7.13;p22.25">Functionalism cannot retain Putnam's claim while remaining neutral about the mind/body question. </s><s n="s8.13;p22.25">Not only this, but the non-physical component in the functional state can play no causal role in the organism's life. </s><s n="s9.13;p22.25">It is entirely redundant and entirely ideal. </s><s n="s10.13;p22.25">Secondly he points to the origin of this line of thinking when he refers to programs. </s><s n="s11.13;p22.25">It is perfectly possible for there to be redundant material in a software program, material that will never be activated. </s><s n="s12.13;p22.25">It is there because it was created for a possible situation the programmer foresaw. </s><s n="s13.13;p22.25">We cannot understand the redundant clauses in the functional definition for organisms in the same way. </s></p><p n="p23.25"><s n="s1.2;p23.25">We have seen that attempts to define a cross-species concept of pain run into serious difficulties. </s><s n="s2.2;p23.25">Stephen Schiffer shows us how hard such a task would be for more complex states by showing how difficult it is (Schiffer believes it is impossible) to functionally define a belief state for human beings.<ref target="BAWE_0235b-ftnote.008"/> The only way possible to get a cross-species definition would be to create an enormous disjunction of input conditions and output conditions that could hardly be considered a definition of a function (as we have argued above) and would be almost certainly impossible to complete, as Schiffer has argued is the case even for a human concept of pain.<ref target="BAWE_0235b-ftnote.009"/> </s></p><note place="foot" id="BAWE_0235b-ftnote.008"><p n="pn1.1"><s n="s1.3;pn1.1">Schiffer, S. </s><s n="s2.3;pn1.1">(1989) 'Remnants of Meaning' Cambridge, Massachusetts: The MIT Press. ch 2. </s><s n="s3.3;pn1.1">Schiffer is working on a physicalist assumption, which is, I take it, the only plausible way a frog could be said to have a belief; I don't think anyone suggests a frog has an ideal, semantic understanding of the world. </s></p></note><note place="foot" id="BAWE_0235b-ftnote.009"><p n="pn1.1"><s n="s1.1;pn1.1">ibid pp. 45-46 </s></p></note><p n="p24.25"><s n="s1.7;p24.25">We have shown that functionalism cannot provide a definition of pain that can apply to all organisms, and thus that although functionalism does avoid some of the faults of behaviourism, it cannot claim this as a further reason for its superiority. </s><s n="s2.7;p24.25">We have also suggested, with Searle, the source of the thinking that leads to this claim. </s><s n="s3.7;p24.25">Nothing we have said directly casts doubt on the viability of functionalism as an explanation of mental states. </s><s n="s4.7;p24.25">However, we have noted in passing that neutrality about the specifically <hi rend="italic">mental</hi> character of mental states may not be an option. </s><s n="s5.7;p24.25">It goes against a very strong intuition that being in pain must at least include having the sensation of pain. </s><s n="s6.7;p24.25">Further, it seems impossible to conceive of a fish having the 'same sort of feeling of pain'. </s><s n="s7.7;p24.25">I don't think this is at all coherent as an idea, and could only be tested by assuming that certain behaviour corresponded to the 'sensation', thereby begging the question. </s></p><p n="p25.25"><s n="s1.2;p25.25">Given that we found a cross-species functional definition of pain could not be given we must conclude by suggesting that the only option for the functionalist is to restrict himself to giving functional definitions for single species and doing so while including the sensation of pain in the definition. </s><s n="s2.2;p25.25">Whether this is a viable position is beyond the scope of this essay. </s></p></div1></body><back><div1 type="bibliography"><head rend="bold">BIBLIOGRAPHY</head><p>Crane, T. (1995) 'The Mechanical Mind' Harmondsworth: Penguin.</p><p>Kripke, S. 'Naming and Necessity' (excerpt), in (1991) <hi rend="italic">The Nature of Mind,</hi> Rosenthal, D (ed.) New York: OUP.</p><p>Lewis, D. 'Psychophysical and Theoretical Identifications' in (1991) <hi rend="italic">The Nature of Mind,</hi> Rosenthal, D (ed.) New York: OUP.</p><p>Putnam, H. 'The Nature of Mental States' in (1991) <hi rend="italic">The Nature of Mind,</hi> Rosenthal, D (ed.) New York: OUP.</p><p>Schiffer, S. (1989) 'Remnants of Meaning', Cambridge, Massachusetts: The MIT Press.</p><p>Searle, J.R. 'Minds, Brains and Programs' in (1991) <hi rend="italic">The Nature of Mind,</hi> Rosenthal, D (ed.) New York: OUP.</p></div1></back></text></TEI.2>
