<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE TEI.2 SYSTEM "tei_bawe.dtd"><TEI.2 id="_6102d" n="version 1.0"><teiHeader><fileDesc><titleStmt><title>[Report for assignment of Virtual reality]</title></titleStmt><extent/><publicationStmt><distributor>British Academic Written English (BAWE) corpus</distributor><availability><p>The British Academic Written English (BAWE) corpus was developed at the Universities of Warwick, Reading and Oxford Brookes, under the directorship of Hilary Nesi and Sheena Gardner (formerly of the Centre for Applied Linguistics [previously called CELTE], Warwick), Paul Thompson (Department of Applied Linguistics, Reading) and Paul Wickens (Westminster Institute of Education, Oxford Brookes), with funding from the ESRC. Subject to the rights of the these institutions in the BAWE corpus, and pursuant to the ESRC agreement, the BAWE corpus is available to researchers for research purposes PROVIDED THAT the following conditions are met:</p><p>1. The corpus files are not distributed in either their original form or in modified form.</p><p>2. The texts are used for research purposes only; they should not be reproduced in teaching materials.</p><p>3. The texts are not reproduced in full for a wider audience/readership, although researchers are free to quote short passages of text (up to 200 running words from any given text).</p><p>4. The BAWE corpus developers (contact: Hilary Nesi) are informed of all projects, dissertations, theses, presentations or publications arising from analysis of the corpus.</p><p>5. Researchers acknowledge their use of the corpus using the following form of words: "The data in this study come from the British Academic Written English (BAWE) corpus, which was developed at the Universities of Warwick, Reading and Oxford Brookes under the directorship of Hilary Nesi and Sheena Gardner (formerly of the Centre for Applied Linguistics [previously called CELTE], Warwick), Paul Thompson (Department of Applied Linguistics, Reading) and Paul Wickens (Westminster Institute of Education, Oxford Brookes), with funding from the ESRC (RES-000-23-0800)."</p></availability></publicationStmt><notesStmt><note resp="British Academic Written English (BAWE) corpus project">Appendix content: figures: 
Appendix A:
The screenshot of the animating: 
Appendix B:
Another model which is not used:
</note></notesStmt><sourceDesc><p n="level">3</p><p n="date">2006-03</p><p n="module title">Virtual Reality</p><p n="module code">CY3F2</p><p n="genre family">Design specification</p><p n="discipline">Cybernetics &amp; Electronic Engineering</p><p n="disciplinary group">PS</p><p n="grade">D</p><p n="number of authors">1</p><p n="number of words">790</p><p n="number of s-units">37</p><p n="number of p">7</p><p n="number of tables">0</p><p n="number of figures">0</p><p n="number of block quotes">0</p><p n="number of formulae">0</p><p n="number of lists">0</p><p n="number of paragraphs formatted like lists">0</p><p n="abstract present">no abstract</p><p n="average words per s-unit">21.4</p><p n="average s-units per p">5.3</p><p n="macrotype of assignment">simple assignment</p></sourceDesc></fileDesc><encodingDesc><p>TEI P4 (documented in: BAWE.documentation.pdf)</p></encodingDesc><profileDesc><particDesc><person><p n="gender">m</p><p n="year of birth">1983</p><p n="first language">Chinese unspecified</p><p n="education">OSa</p><p n="course">MEng</p><p n="student ID">6102</p></person></particDesc></profileDesc></teiHeader><text><front><titlePage><docTitle><titlePart rend="bold">Report for assignment of Virtual reality </titlePart></docTitle><titlePart rend="bold"><name type="student name"/><name type="other"/></titlePart></titlePage></front><body><div1 type="section"><head rend="bold">Introduction</head><p n="p1.7"><s n="s1.5;p1.7">Virtual reality (VR) is a computer simulation virtual environment. </s><s n="s2.5;p1.7">Most virtual reality environments are primarily visual experiences, displayed on a computer. </s><s n="s3.5;p1.7">Users can interact with a virtual environment either through the use of standard input devices such as a keyboard and mouse. </s><s n="s4.5;p1.7">Normally, OpenSG which is a portable scene-graph system to create real time graphics programs associated with Maya or Blender which is applied to design 3D avatar are used to create a VR system. </s><s n="s5.5;p1.7">In this assignment a model is established, and then it is loaded into a VR environment designed by OpenSG and animated. </s></p></div1><div1 type="section"><head rend="bold">Description </head><p n="p2.7"><s n="s1.11;p2.7">In this group, I am the "third person" who concentrates animating the model designed by the first person through Maya package. </s><s n="s2.11;p2.7">Surely the model has been loaded into a VR environment established with OpenSG by the second person. </s><s n="s3.11;p2.7">The model in this group is a cube matrix constructed by 625 cubes unities colored with rainbow style. </s><s n="s4.11;p2.7">As the third person in this group, what I have done is to design program to rotate the cube matrix and make it interactive with keyboard and mouse. </s><s n="s5.11;p2.7">For the rotation stuff, eight different axis are set to be rotated around. </s><s n="s6.11;p2.7">Also there is reaction to mouse motion with pressed buttons. </s><s n="s7.11;p2.7">Rolling the middle button of mouse forward and backward, the viewpoint on the object will be zoomed in and zoomed out and holding the left button the object can be driven to move around the drawn window. </s><s n="s8.11;p2.7">Moreover, the interesting interaction with the object is on keyboard. </s><s n="s9.11;p2.7">Pressing the button "a" to "k", the rotational axis will be changed correspondently and around the current axis go on rotating. </s><s n="s10.11;p2.7">To make the scene more brilliant, I load a beautiful astronomy picture M101 which is spiral nebulae as the background of the animation. </s><s n="s11.11;p2.7">So a cube matrix rotation in galaxy atmosphere associated with keyboard and mouse interaction is produced through OpenSG library. </s></p></div1><div1 type="section"><head rend="bold">Methods </head><p n="p3.7"><s n="s1.9;p3.7">The approach which is used to design the animation is Quaternion. </s><s n="s2.9;p3.7">Quaternion is a quick and effective solution to rotation. </s><s n="s3.9;p3.7">They are described by an angle and a vector. </s><s n="s4.9;p3.7">The angle is the amount which is wanted to rotate around the vector provided. </s><s n="s5.9;p3.7">The vector defines the axis which will rotate the entire scene with the provided angle. </s><s n="s6.9;p3.7">So it is possible to realize the custom rotations around any axis. </s><s n="s7.9;p3.7">In the display function of the program, a matrix is set to do the transformation stuff. </s><s n="s8.9;p3.7">"Quaternion q = Quaternion (Vec3f(A,B,C), r);" and "m.setRotate(q);" are called to start to transform. </s><s n="s9.9;p3.7">Also when the specific model loaded into the VR environment by the second person is needed to be modified, the Editing Field Containers "begin-/endEditCP" associated with the field mark "Transform::MatrixFieldMask" which is to set the matrix of a transform core should be called, then set the radians to process the model rotation. </s></p><p n="p4.7"><s n="s1.5;p4.7">The interaction stuffs are realized in the GLUT. Through the GLUT the keyboard and mouse can be accessed easily. </s><s n="s2.5;p4.7">After registering and initializing the keyboard and mouse callback function to listen to the input, they will be called in GLUT if the corresponding event occurs such as the keyboard callback is invoked when a key is pressed, the mouse callback when the mouse button is pressed and so on. </s><s n="s3.5;p4.7">So before "setupGLUT" function, the keyboard function is set and use state machine to return the "A,B,C" value of "vec3f(A,B,C)" in "Quaternion". </s><s n="s4.5;p4.7">The three parameters are changed with preprogrammed eight values from "0 0 0" to "1 1 1" to react the correspondent keyboard input "a s d f g h j k" respectively. </s><s n="s5.5;p4.7">So the interaction between the object and keyboard pressed is set successfully. </s></p><p n="p5.7"><s n="s1.3;p5.7">The last job I have done is loading a picture as the background. </s><s n="s2.3;p5.7">First a picture which will be the background should be loaded in with "ImagePtr img = Image::create();img->read(" ");" Images in OpenSG are stored in a field container class called "Image". </s><s n="s3.3;p5.7">And then set it as background with "osg::ImageBackground". </s></p><p n="p6.7"><s n="s1.1;p6.7">To sum up, all the above programming work is done in KDevelop(C/C++) under linux OS installed the OpenSG. </s></p><p n="p7.7"><s n="s1.3;p7.7">In this group, I focus on the animating model and interaction in OpenSG. Brian concentrates on the Maya stuff to create the model and Olly Tanar is responsible for how to load model into the VR environment with OpenSG. Moreover Brian and Olly assist me to figure out many programming stuff on animating and interaction. </s><s n="s2.3;p7.7">Meanwhile, I join the design work to create some models with Brian, though only one is engaged into this project. </s><s n="s3.3;p7.7">Furthermore, we also ask a help from David Padbury group on how to load an image as background and he gives us some reasonable suggestions on animating. </s></p></div1></body><back><div1 type="appendix"><head>Appendix A: The screenshot of the animating: </head><p/></div1><div1 type="appendix"><head>Appendix B: Another model which is not used:</head><p/></div1></back></text></TEI.2>
